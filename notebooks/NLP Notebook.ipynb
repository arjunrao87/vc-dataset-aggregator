{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = \"TravelTriangle, an Indian marketplace for finding and booking travel and holidays, raised $10 million in Series B funding, according to TechCrunch. RB Investments led the round, and was joined by SAIF Partners and Bessemer Venture Partners. Read more\"\n",
    "word_list = word_tokenize(raw)\n",
    "filtered_words = [word for word in word_list if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TravelTriangle', ',', 'Indian', 'marketplace', 'finding', 'booking', 'travel', 'holidays', ',', 'raised', '$', '10', 'million', 'Series', 'B', 'funding', ',', 'according', 'TechCrunch', '.', 'RB', 'Investments', 'led', 'round', ',', 'joined', 'SAIF', 'Partners', 'Bessemer', 'Venture', 'Partners', '.', 'Read']\n"
     ]
    }
   ],
   "source": [
    "print( filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_filtered_words = []\n",
    "count = 0\n",
    "for word in filtered_words :\n",
    "    if word == \".\" or word == \",\":\n",
    "        continue\n",
    "    new_filtered_words.insert(count, word)\n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TravelTriangle', 'Indian', 'marketplace', 'finding', 'booking', 'travel', 'holidays', 'raised', '$', '10', 'million', 'Series', 'B', 'funding', 'according', 'TechCrunch', 'RB', 'Investments', 'led', 'round', 'joined', 'SAIF', 'Partners', 'Bessemer', 'Venture', 'Partners', 'Read']\n"
     ]
    }
   ],
   "source": [
    "print( new_filtered_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_string = \" \".join ( new_filtered_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TravelTriangle Indian marketplace finding booking travel holidays raised $ 10 million Series B funding according TechCrunch RB Investments led round joined SAIF Partners Bessemer Venture Partners Read\n"
     ]
    }
   ],
   "source": [
    "print ( filtered_string )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "def ngram_it( sentence, n ):\n",
    "    sixgrams = ngrams(sentence.split(), n)\n",
    "    for grams in sixgrams:\n",
    "      print (grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TravelTriangle', 'Indian', 'marketplace')\n",
      "('Indian', 'marketplace', 'finding')\n",
      "('marketplace', 'finding', 'booking')\n",
      "('finding', 'booking', 'travel')\n",
      "('booking', 'travel', 'holidays')\n",
      "('travel', 'holidays', 'raised')\n",
      "('holidays', 'raised', '$')\n",
      "('raised', '$', '10')\n",
      "('$', '10', 'million')\n",
      "('10', 'million', 'Series')\n",
      "('million', 'Series', 'B')\n",
      "('Series', 'B', 'funding')\n",
      "('B', 'funding', 'according')\n",
      "('funding', 'according', 'TechCrunch')\n",
      "('according', 'TechCrunch', 'RB')\n",
      "('TechCrunch', 'RB', 'Investments')\n",
      "('RB', 'Investments', 'led')\n",
      "('Investments', 'led', 'round')\n",
      "('led', 'round', 'joined')\n",
      "('round', 'joined', 'SAIF')\n",
      "('joined', 'SAIF', 'Partners')\n",
      "('SAIF', 'Partners', 'Bessemer')\n",
      "('Partners', 'Bessemer', 'Venture')\n",
      "('Bessemer', 'Venture', 'Partners')\n",
      "('Venture', 'Partners', 'Read')\n"
     ]
    }
   ],
   "source": [
    "ngram_it( filtered_string, 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TravelTriangle Indian marketplace finding booking travel holidays raised $ 10 million Series B funding according TechCrunch RB Investments led round joined SAIF Partners Bessemer Venture Partners Read'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_entities(text_list):\n",
    "    entities=set()\n",
    "    for sentence in text_list:\n",
    "        try:\n",
    "\n",
    "            tokens = nltk.word_tokenize(sentence)\n",
    "            print( \"tokens = \", tokens )\n",
    "            tagged = nltk.pos_tag(tokens)\n",
    "            print( \"tagged = \", tagged )\n",
    "            [entities.add(word.lower()) for word,pos in tagged\n",
    "                 if pos in ['NN','NNP','NNS','NNPS','JJ','VBS','VBN','VBG','VBD']]\n",
    "\n",
    "        except Exception as e:\n",
    "            print('stage 1',e)\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens =  ['TravelTriangle', 'Indian', 'marketplace', 'finding', 'booking', 'travel', 'holidays', 'raised', '$', '10', 'million', 'Series', 'B', 'funding', 'according', 'TechCrunch', 'RB', 'Investments', 'led', 'round', 'joined', 'SAIF', 'Partners', 'Bessemer', 'Venture', 'Partners', 'Read']\n",
      "tagged =  [('TravelTriangle', 'NNP'), ('Indian', 'JJ'), ('marketplace', 'NN'), ('finding', 'VBG'), ('booking', 'VBG'), ('travel', 'NN'), ('holidays', 'NNS'), ('raised', 'VBD'), ('$', '$'), ('10', 'CD'), ('million', 'CD'), ('Series', 'NNP'), ('B', 'NNP'), ('funding', 'VBG'), ('according', 'VBG'), ('TechCrunch', 'NNP'), ('RB', 'NNP'), ('Investments', 'NNP'), ('led', 'VBD'), ('round', 'NN'), ('joined', 'VBD'), ('SAIF', 'NNP'), ('Partners', 'NNPS'), ('Bessemer', 'NNP'), ('Venture', 'NNP'), ('Partners', 'NNP'), ('Read', 'NNP')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'according',\n",
       " 'b',\n",
       " 'bessemer',\n",
       " 'booking',\n",
       " 'finding',\n",
       " 'funding',\n",
       " 'holidays',\n",
       " 'indian',\n",
       " 'investments',\n",
       " 'joined',\n",
       " 'led',\n",
       " 'marketplace',\n",
       " 'partners',\n",
       " 'raised',\n",
       " 'rb',\n",
       " 'read',\n",
       " 'round',\n",
       " 'saif',\n",
       " 'series',\n",
       " 'techcrunch',\n",
       " 'travel',\n",
       " 'traveltriangle',\n",
       " 'venture'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_entities( [filtered_string] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson_developer_cloud in /anaconda/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: pysolr<4.0,>=3.3 in /anaconda/lib/python3.6/site-packages (from watson_developer_cloud)\n",
      "Requirement already up-to-date: requests<3.0,>=2.0 in /anaconda/lib/python3.6/site-packages (from watson_developer_cloud)\n",
      "Requirement already up-to-date: pyOpenSSL>=16.2.0 in /anaconda/lib/python3.6/site-packages (from watson_developer_cloud)\n",
      "Requirement already up-to-date: urllib3<1.23,>=1.21.1 in /anaconda/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: idna<2.7,>=2.5 in /anaconda/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: chardet<3.1.0,>=3.0.2 in /anaconda/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /anaconda/lib/python3.6/site-packages (from requests<3.0,>=2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: six>=1.5.2 in /anaconda/lib/python3.6/site-packages (from pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: cryptography>=1.9 in /anaconda/lib/python3.6/site-packages (from pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: asn1crypto>=0.21.0 in /anaconda/lib/python3.6/site-packages (from cryptography>=1.9->pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: cffi>=1.7 in /anaconda/lib/python3.6/site-packages (from cryptography>=1.9->pyOpenSSL>=16.2.0->watson_developer_cloud)\n",
      "Requirement already up-to-date: pycparser in /anaconda/lib/python3.6/site-packages (from cffi>=1.7->cryptography>=1.9->pyOpenSSL>=16.2.0->watson_developer_cloud)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade watson_developer_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 1,\n",
      "    \"text_characters\": 229,\n",
      "    \"features\": 2\n",
      "  },\n",
      "  \"language\": \"en\",\n",
      "  \"keywords\": [\n",
      "    {\n",
      "      \"text\": \"Norwest Venture Partners\",\n",
      "      \"relevance\": 0.970348\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"open-source networking company\",\n",
      "      \"relevance\": 0.929664\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Palo Alto\",\n",
      "      \"relevance\": 0.814973\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Series A funding\",\n",
      "      \"relevance\": 0.701057\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Microsoft Ventures\",\n",
      "      \"relevance\": 0.658689\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Lightspeed\",\n",
      "      \"relevance\": 0.462883\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"Fortune\",\n",
      "      \"relevance\": 0.418066\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"SnapRoute\",\n",
      "      \"relevance\": 0.354296\n",
      "    },\n",
      "    {\n",
      "      \"text\": \"AT&T\",\n",
      "      \"relevance\": 0.345415\n",
      "    }\n",
      "  ],\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"Norwest Venture Partners\",\n",
      "      \"relevance\": 0.986409,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [],\n",
      "        \"name\": \"Norwest Venture Partners\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Norwest_Venture_Partners\"\n",
      "      },\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Palo Alto\",\n",
      "      \"relevance\": 0.775662,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"City\"\n",
      "        ],\n",
      "        \"name\": \"Palo Alto, California\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Palo_Alto,_California\"\n",
      "      },\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"Microsoft Ventures\",\n",
      "      \"relevance\": 0.521325,\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"Lightspeed\",\n",
      "      \"relevance\": 0.484181,\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"Fortune\",\n",
      "      \"relevance\": 0.423153,\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"AT&T\",\n",
      "      \"relevance\": 0.264308,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"SoftwareDeveloper\",\n",
      "          \"VideoGamePublisher\"\n",
      "        ],\n",
      "        \"name\": \"AT&T\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/AT&T\"\n",
      "      },\n",
      "      \"count\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Quantity\",\n",
      "      \"text\": \"$25 million\",\n",
      "      \"relevance\": 0.264308,\n",
      "      \"count\": 1\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from watson_developer_cloud import NaturalLanguageUnderstandingV1\n",
    "import watson_developer_cloud.natural_language_understanding.features.v1 \\\n",
    "  as Features\n",
    "\n",
    "natural_language_understanding = NaturalLanguageUnderstandingV1(\n",
    "  username=\"84d36206-9e5e-401c-862b-5181ae136925\",\n",
    "  password=\"nMOAsgSHskbY\",\n",
    "  version=\"2017-02-27\")\n",
    "\n",
    "response = natural_language_understanding.analyze(\n",
    "  text= \"SnapRoute, a Palo Alto, Calif.-based open-source networking company, raised $25 million in Series A funding. Norwest Venture Partners led the round, and was joined by Lightspeed, AT&T, and Microsoft Ventures. Read more at Fortune\",\n",
    "  features=[\n",
    "    Features.Entities(\n",
    "      limit=30\n",
    "    ),\n",
    "    Features.Keywords(\n",
    "      limit=30\n",
    "    )\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.1.tar.gz\n",
      "Requirement already satisfied: nltk in /anaconda/lib/python3.6/site-packages (from rake-nltk)\n",
      "Requirement already satisfied: six in /anaconda/lib/python3.6/site-packages (from nltk->rake-nltk)\n",
      "Building wheels for collected packages: rake-nltk\n",
      "  Running setup.py bdist_wheel for rake-nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/arjunrao/Library/Caches/pip/wheels/b8/7c/e3/20d8be4bf718c35205283ba458d41690d4a1f3b26dc45e54ba\n",
      "Successfully built rake-nltk\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = Rake([\"the\", \"and\", \"by\",\"in\", \"raised\", \"was\", \"other\", \"joined\", \"round\", \"-\", \"based\",\"has\",\"fortune\", \"read\", \"more\", \"from\", \"an\"], [\",\"]) # Uses stopwords for english from NLTK, and all puntuation characters.\n",
    "text = \" Galore, a San Francisco-based mobile app that allows parents to book activities for their children, raised $1.65 million in seed funding. Norwest Venture Partners and DCM Ventures led the round\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'Marketplace', 'For', 'Finding']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led', '$', '10', 'Million']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led', '$', '10', 'Million', 'Saif', 'Partners']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led', '$', '10', 'Million', 'Saif', 'Partners', 'Booking', 'Travel']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led', '$', '10', 'Million', 'Saif', 'Partners', 'Booking', 'Travel', 'Traveltriangle']\n",
      "['India', 'Marketplace', 'For', 'Finding', 'According', 'To', 'Techcrunch', '.', 'Bessemer', 'Venture', 'Partners', '.', 'Series', 'B', 'Funding', 'Rb', 'Investments', 'Led', '$', '10', 'Million', 'Saif', 'Partners', 'Booking', 'Travel', 'Traveltriangle', 'Holidays']\n"
     ]
    }
   ],
   "source": [
    "r.extract_keywords_from_text(text)\n",
    "phrases = r.get_ranked_phrases()\n",
    "all_words = []\n",
    "for phrase in phrases :\n",
    "    phrase = phrase.title()\n",
    "    words = word_tokenize( phrase )\n",
    "    all_words = all_words + words \n",
    "    print (all_words)\n",
    "# r.rank_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens =  ['an', 'Ohio']\n",
      "tagged =  [('an', 'DT'), ('Ohio', 'NNP')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ohio'}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"an Ohio\"\n",
    "extract_entities( [sent] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geotext\n",
      "  Downloading geotext-0.3.0-py2.py3-none-any.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 211kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: geotext\n",
      "Successfully installed geotext-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install geotext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geotext import GeoText\n",
    "places = GeoText(\"Stem is Ohio-based\")\n",
    "places.cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geograpy\n",
      "  Using cached geograpy-0.3.7.tar.gz\n",
      "Requirement already satisfied: numpy in /anaconda/lib/python3.6/site-packages (from geograpy)\n",
      "Requirement already satisfied: nltk in /anaconda/lib/python3.6/site-packages (from geograpy)\n",
      "Collecting newspaper (from geograpy)\n",
      "  Using cached newspaper-0.1.0.7.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    \u001b[31;1mWARNING! You are attempting to install newspaper's python2 repository on python3. PLEASE RUN `$ pip3 install newspaper3k` for python3 or `$ pip install newspaper` for python2\u001b[0m\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /private/var/folders/qj/bf9rqc9d2nd2krx3k56_xddm0000gn/T/pip-build-ti_3s5so/newspaper/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in /anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: PyYAML>=3.11 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: requests>=2.10.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k)\n",
      "Requirement already satisfied: six in /anaconda/lib/python3.6/site-packages (from nltk>=3.2.1->newspaper3k)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k)\n",
      "Requirement already satisfied: setuptools in /anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from tldextract>=2.0.1->newspaper3k)\n",
      "Requirement already satisfied: requests-file>=1.4 in /anaconda/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k)\n",
      "Requirement already satisfied: olefile in /anaconda/lib/python3.6/site-packages (from Pillow>=3.3.0->newspaper3k)\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/reach2ashish/geograpy.git\n",
      "  Cloning https://github.com/reach2ashish/geograpy.git to /private/var/folders/qj/bf9rqc9d2nd2krx3k56_xddm0000gn/T/pip-zidixhak-build\n",
      "  Requirement already satisfied (use --upgrade to upgrade): geograpy==0.3.7 from git+https://github.com/reach2ashish/geograpy.git in /anaconda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /anaconda/lib/python3.6/site-packages (from geograpy==0.3.7)\n",
      "Requirement already satisfied: nltk in /anaconda/lib/python3.6/site-packages (from geograpy==0.3.7)\n",
      "Requirement already satisfied: newspaper3k in /anaconda/lib/python3.6/site-packages (from geograpy==0.3.7)\n",
      "Requirement already satisfied: jellyfish in /anaconda/lib/python3.6/site-packages (from geograpy==0.3.7)\n",
      "Requirement already satisfied: pycountry in /anaconda/lib/python3.6/site-packages (from geograpy==0.3.7)\n",
      "Requirement already satisfied: six in /anaconda/lib/python3.6/site-packages (from nltk->geograpy==0.3.7)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: requests>=2.10.0 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in /anaconda/lib/python3.6/site-packages (from newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: idna in /anaconda/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: setuptools in /anaconda/lib/python3.6/site-packages/setuptools-27.2.0-py3.6.egg (from tldextract>=2.0.1->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: requests-file>=1.4 in /anaconda/lib/python3.6/site-packages (from tldextract>=2.0.1->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: olefile in /anaconda/lib/python3.6/site-packages (from Pillow>=3.3.0->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k->geograpy==0.3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/lib/python3.6/site-packages (from requests>=2.10.0->newspaper3k->geograpy==0.3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/reach2ashish/geograpy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'extraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-f709ff6fee11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeograpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/geograpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mextraction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplaces\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPlaceContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_place_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'extraction'"
     ]
    }
   ],
   "source": [
    "import geograpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Corollarium/geograpy2\n",
      "  Cloning https://github.com/Corollarium/geograpy2 to /private/var/folders/qj/bf9rqc9d2nd2krx3k56_xddm0000gn/T/pip-8dsx0tn9-build\n",
      "Requirement already satisfied: numpy in /anaconda/lib/python3.6/site-packages (from geograpy2==0.1.0)\n",
      "Requirement already satisfied: nltk in /anaconda/lib/python3.6/site-packages (from geograpy2==0.1.0)\n",
      "Collecting newspaper (from geograpy2==0.1.0)\n",
      "  Using cached newspaper-0.1.0.7.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    \u001b[31;1mWARNING! You are attempting to install newspaper's python2 repository on python3. PLEASE RUN `$ pip3 install newspaper3k` for python3 or `$ pip install newspaper` for python2\u001b[0m\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /private/var/folders/qj/bf9rqc9d2nd2krx3k56_xddm0000gn/T/pip-build-3xmug6kn/newspaper/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Corollarium/geograpy2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/dat/pyner\n",
      "  Cloning https://github.com/dat/pyner to /private/var/folders/qj/bf9rqc9d2nd2krx3k56_xddm0000gn/T/pip-4jfhv_gi-build\n",
      "Installing collected packages: ner\n",
      "  Running setup.py install for ner ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed ner-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/dat/pyner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.quora.com/What-are-the-best-python-libraries-for-extracting-location-from-text\n",
    "# http://textminingonline.com/how-to-use-stanford-named-entity-recognizer-ner-in-python-nltk-and-other-programming-languages\n",
    "# https://pythonprogramming.net/named-entity-recognition-stanford-ner-tagger/\n",
    "# https://nlp.stanford.edu/software/CRF-NER.shtml#Download\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('/Users/arjunrao/Downloads/stanford-ner-2017-06-09/classifiers/english.all.3class.distsim.crf.ser.gz','/Users/arjunrao/Downloads/stanford-ner-2017-06-09/stanford-ner.jar',encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Galore', 'O'), (',', 'O'), ('a', 'O'), ('San', 'O'), ('Francisco-', 'O'), ('mobile', 'O'), ('app', 'O'), ('that', 'O'), ('allows', 'O'), ('parents', 'O'), ('to', 'O'), ('book', 'O'), ('activities', 'O'), ('for', 'O'), ('their', 'O'), ('children', 'O'), (',', 'O'), ('raised', 'O'), ('$', 'O'), ('1.65', 'O'), ('million', 'O'), ('in', 'O'), ('seed', 'O'), ('funding', 'O'), ('.', 'O'), ('Norwest', 'ORGANIZATION'), ('Venture', 'ORGANIZATION'), ('Partners', 'ORGANIZATION'), ('and', 'O'), ('DCM', 'ORGANIZATION'), ('Ventures', 'ORGANIZATION'), ('led', 'O'), ('the', 'O'), ('round', 'O')]\n"
     ]
    }
   ],
   "source": [
    "text = \" Galore, a San Francisco- mobile app that allows parents to book activities for their children, raised $1.65 million in seed funding. Norwest Venture Partners and DCM Ventures led the round\"\n",
    "tokenized_text = word_tokenize(text)\n",
    "classified_text = st.tag(tokenized_text)\n",
    "print(classified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indian'"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "snowball_stemmer.stem('indian')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Norwest Venture Partners', 'DCM Ventures']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "    vc_firms = []\n",
    "    current_vc_firm = []\n",
    "    locations = []\n",
    "    current_location = []\n",
    "    previous_classification = None\n",
    "    for phrase in classified_text :\n",
    "        if( phrase[1] == \"LOCATION\" ):\n",
    "            current_location.append( phrase[0])\n",
    "            previous_classification = \"LOCATION\"\n",
    "        if ( phrase[1] == \"O\" and previous_classification == \"LOCATION\" ):\n",
    "                previous_classification = None\n",
    "                current_location_string = \" \".join( current_location )\n",
    "                locations.append(current_location_string)\n",
    "                current_location = []\n",
    "        if( phrase[1] == \"ORGANIZATION\" or phrase[1] == \"PERSON\" ):\n",
    "            current_vc_firm.append(phrase[0])\n",
    "            previous_classification = \"ORGANIZATION\"\n",
    "        if ( phrase[1] == \"O\" and previous_classification == \"ORGANIZATION\" ):\n",
    "            if( current_vc_firm ):\n",
    "                previous_classification = None\n",
    "                current_vc_firm_string = \" \".join( current_vc_firm )\n",
    "                vc_firms.append(current_vc_firm_string)\n",
    "                current_vc_firm = []\n",
    "    if current_vc_firm and current_vc_firm not in vc_firms:\n",
    "        current_vc_firm_string = \" \".join( current_vc_firm )\n",
    "        vc_firms.append( current_vc_firm_string )\n",
    "    if current_location and current_location not in locations:\n",
    "        current_location_string = \" \".join( current_location )\n",
    "        locations.append( current_location_string )\n",
    "    print ( vc_firms )\n",
    "    print ( locations )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
